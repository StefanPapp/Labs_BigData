#Scope
These series targets to help students to learn Apache Spark. This tutorial was built for Spark 2.2. 

# Prerequirements
We can divide into two execution environments: Local and remote

The local execution can be performed with Linux, Windows and Mac OS X. 

The installation of tools include
* JAVA
* Python
* Scala
* Maven
* Git

The remote will be executed in a remote environment
* DataBricks Cloud
* we need a web browser 

#Directory
We use for the execution of samples

/workspace/lab/spark
/workspace/app/spark/<spark-version-name>

#Recommendation
use zsh and z 